{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ficbook_gpt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RHDK81QqrET"
      },
      "source": [
        "# Finetune ruGPT3Small on fun fiction collection\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK10D3MSpYty"
      },
      "source": [
        "## Install enviroment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asqMueYPeIgK"
      },
      "source": [
        "!pip3 install urllib3==1.25.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPqtVgbkeTx7"
      },
      "source": [
        "!pip3 install transformers==2.8.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpkjTWefecLc"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/sberbank-ai/ru-gpts/master/pretrain_transformers.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7zu3BqpqJQ7"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/sberbank-ai/ru-gpts/master/generate_transformers.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlJB3Ln7gjO9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28fc4576-fb95-4ac3-d0b2-dd5583d93f95"
      },
      "source": [
        "%%writefile setup.sh\n",
        "\n",
        "export CUDA_HOME=/usr/local/cuda-10.1\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing setup.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAZqpSEJglUl"
      },
      "source": [
        "!sh setup.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTN7lA4BqbRz"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5EtK-jerBRv"
      },
      "source": [
        "data_path = \"drive/My Drive/GPT/fanfics.txt\"\n",
        "!ls \"$data_path\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU1_MKSy88zV"
      },
      "source": [
        "DATA_HOME = \"drive/My Drive/GPT/data\"\n",
        "!ls \"$DATA_HOME\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDYi1TVTrtkO"
      },
      "source": [
        "## Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXdNbrq3rgzq"
      },
      "source": [
        "with open(data_path, \"r\") as file:\n",
        "    text = file.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sgqpozwryu_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5XsmNzor0pK"
      },
      "source": [
        "texts_df = pd.DataFrame(text, columns=['text'])\n",
        "train_df = texts_df.sample(frac=.8)\n",
        "test_df = texts_df[~texts_df.index.isin(train_df.index)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW241IAS5Ez0"
      },
      "source": [
        "def save_text_df(df, filename):\n",
        "    with open(filename, \"w\") as f:\n",
        "        for idx in df.index:\n",
        "            text = df.loc[idx, 'text']\n",
        "            f.write(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Izc0lkkHr2Rz"
      },
      "source": [
        "save_text_df(train_df, DATA_HOME + \"/train.txt\")\n",
        "save_text_df(test_df, DATA_HOME + \"/test.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NitGcEKPsDQE"
      },
      "source": [
        "## Run finetuning\n",
        "The following code download our model and tokenizer from transformers and finetune model essays.\n",
        "\n",
        "This took aroung ten minutes and obtain perplexity = 13-16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98X-BKW2xfpc"
      },
      "source": [
        "!unzip \"$DATA_HOME/fanfics_1_epoch.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vL07XFvsBBU"
      },
      "source": [
        "!python pretrain_transformers.py \\\n",
        "    --output_dir=fanfics_model \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path=fanfics_model/checkpoint-17000 \\\n",
        "    --do_train \\\n",
        "    --train_data_file=\"$DATA_HOME/train.txt\" \\\n",
        "    --do_eval \\\n",
        "    --fp16 \\\n",
        "    --eval_data_file=\"$DATA_HOME/test.txt\" \\\n",
        "    --per_gpu_train_batch_size 1 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --num_train_epochs 5 \\\n",
        "    --block_size 2048 \\\n",
        "    --eval_all_checkpoints \\\n",
        "    --overwrite_output_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCEOB46Lctik",
        "outputId": "c90dae69-51d8-473c-9179-a4cb9318a40a"
      },
      "source": [
        "!tensorboard --inspect --event_file=/content/runs/Dec20_20-31-15_c81ee3f61962/events.out.tfevents.1608496275.c81ee3f61962.4314.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-20 21:29:12.777217: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "======================================================================\n",
            "Processing event files... (this can take a few minutes)\n",
            "======================================================================\n",
            "\n",
            "These tags are in /content/runs/Dec20_20-31-15_c81ee3f61962/events.out.tfevents.1608496275.c81ee3f61962.4314.0:\n",
            "audio -\n",
            "histograms -\n",
            "images -\n",
            "scalars\n",
            "   loss\n",
            "   lr\n",
            "tensor -\n",
            "======================================================================\n",
            "\n",
            "Event statistics for /content/runs/Dec20_20-31-15_c81ee3f61962/events.out.tfevents.1608496275.c81ee3f61962.4314.0:\n",
            "audio -\n",
            "graph -\n",
            "histograms -\n",
            "images -\n",
            "scalars\n",
            "   first_step           14500\n",
            "   last_step            17000\n",
            "   max_step             17000\n",
            "   min_step             14500\n",
            "   num_steps            6\n",
            "   outoforder_steps     []\n",
            "sessionlog:checkpoint -\n",
            "sessionlog:start -\n",
            "sessionlog:stop -\n",
            "tensor -\n",
            "======================================================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2N6ylGPt1F5"
      },
      "source": [
        "## Check our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJmVBKtyD3y7"
      },
      "source": [
        "from tensorflow.python.summary.summary_iterator import summary_iterator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pNfJ2jgD5dH",
        "outputId": "206bf9a7-abe2-4cf4-8199-7672848e0fff"
      },
      "source": [
        "for summary in summary_iterator(\"/content/runs/Dec20_20-31-15_c81ee3f61962/events.out.tfevents.1608496275.c81ee3f61962.4314.0\"):\n",
        "    print(summary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/summary/summary_iterator.py:31: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "wall_time: 1608496275.9209788\n",
            "file_version: \"brain.Event:2\"\n",
            "\n",
            "wall_time: 1608496597.4696038\n",
            "step: 14500\n",
            "summary {\n",
            "  value {\n",
            "    tag: \"lr\"\n",
            "    simple_value: 4.970543159288354e-05\n",
            "  }\n",
            "}\n",
            "\n",
            "wall_time: 1608496597.4697087\n",
            "step: 14500\n",
            "summary {\n",
            "  value {\n",
            "    tag: \"loss\"\n",
            "    simple_value: 3.4174423217773438\n",
            "  }\n",
            "}\n",
            "\n",
            "wall_time: 1608496932.0207539\n",
            "step: 15000\n",
            "summary {\n",
            "  value {\n",
            "    tag: \"lr\"\n",
            "    simple_value: 4.9410864448873326e-05\n",
            "  }\n",
            "}\n",
            "\n",
            "wall_time: 1608496932.020882\n",
            "step: 15000\n",
            "summary {\n",
            "  value {\n",
            "    tag: \"loss\"\n",
            "    simple_value: 3.423922538757324\n",
            "  }\n",
            "}\n",
            "\n",
            "wall_time: 1608497266.7529678\n",
            "step: 15500\n",
            "summary {\n",
            "  value {\n",
            "    tag: \"lr\"\n",
            "    simple_value: 4.911629730486311e-05\n",
            "  }\n",
            "}\n",
            "\n",
            "wall_time: 1608497266.7531455\n",
            "step: 15500\n",
            "summary {\n",
            "  value {\n",
            "    tag: \"loss\"\n",
            "    simple_value: 3.414184808731079\n",
            "  }\n",
            "}\n",
            "\n",
            "wall_time: 1608497601.7439253\n",
            "step: 16000\n",
            "summary {\n",
            "  value {\n",
            "    tag: \"lr\"\n",
            "    simple_value: 4.882172652287409e-05\n",
            "  }\n",
            "}\n",
            "\n",
            "wall_time: 1608497601.7440355\n",
            "step: 16000\n",
            "summary {\n",
            "  value {\n",
            "    tag: \"loss\"\n",
            "    simple_value: 3.4136266708374023\n",
            "  }\n",
            "}\n",
            "\n",
            "wall_time: 1608497936.7320266\n",
            "step: 16500\n",
            "summary {\n",
            "  value {\n",
            "    tag: \"lr\"\n",
            "    simple_value: 4.852715937886387e-05\n",
            "  }\n",
            "}\n",
            "\n",
            "wall_time: 1608497936.732164\n",
            "step: 16500\n",
            "summary {\n",
            "  value {\n",
            "    tag: \"loss\"\n",
            "    simple_value: 3.450991153717041\n",
            "  }\n",
            "}\n",
            "\n",
            "wall_time: 1608498271.972373\n",
            "step: 17000\n",
            "summary {\n",
            "  value {\n",
            "    tag: \"lr\"\n",
            "    simple_value: 4.8232592234853655e-05\n",
            "  }\n",
            "}\n",
            "\n",
            "wall_time: 1608498271.9725258\n",
            "step: 17000\n",
            "summary {\n",
            "  value {\n",
            "    tag: \"loss\"\n",
            "    simple_value: 3.4224793910980225\n",
            "  }\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9VXkISjFV2q"
      },
      "source": [
        "!zip -r fanfics_1_epoch.zip fanfics_model/checkpoint-17000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRlAAsIbsHdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b006b7a-3277-44be-d65a-34a835c680a4"
      },
      "source": [
        "!python generate_transformers.py \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path=fanfics_model/checkpoint-17000 \\\n",
        "    --k=5 \\\n",
        "    --p=0.95 \\\n",
        "    --length=200"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-21 14:51:19.792265: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "12/21/2020 14:51:22 - INFO - transformers.tokenization_utils -   Model name 'fanfics_model/checkpoint-17000' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'fanfics_model/checkpoint-17000' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "12/21/2020 14:51:22 - INFO - transformers.tokenization_utils -   Didn't find file fanfics_model/checkpoint-17000/added_tokens.json. We won't load it.\n",
            "12/21/2020 14:51:22 - INFO - transformers.tokenization_utils -   loading file fanfics_model/checkpoint-17000/vocab.json\n",
            "12/21/2020 14:51:22 - INFO - transformers.tokenization_utils -   loading file fanfics_model/checkpoint-17000/merges.txt\n",
            "12/21/2020 14:51:22 - INFO - transformers.tokenization_utils -   loading file None\n",
            "12/21/2020 14:51:22 - INFO - transformers.tokenization_utils -   loading file fanfics_model/checkpoint-17000/special_tokens_map.json\n",
            "12/21/2020 14:51:22 - INFO - transformers.tokenization_utils -   loading file fanfics_model/checkpoint-17000/tokenizer_config.json\n",
            "12/21/2020 14:51:22 - INFO - transformers.configuration_utils -   loading configuration file fanfics_model/checkpoint-17000/config.json\n",
            "12/21/2020 14:51:22 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"_num_labels\": 2,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"finetuning_task\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 2048,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 2048,\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "12/21/2020 14:51:22 - INFO - transformers.modeling_utils -   loading weights file fanfics_model/checkpoint-17000/pytorch_model.bin\n",
            "12/21/2020 14:51:41 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=5, length=200, model_name_or_path='fanfics_model/checkpoint-17000', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=1, p=0.95, padding_text='', prompt='', repetition_penalty=1.0, seed=42, stop_token='</s>', temperature=1.0, xlm_language='')\n",
            "Context >>> Он взял ее за руку и\n",
            "12/21/2020 14:52:23 - WARNING - transformers.modeling_utils -   Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
            "ruGPT:\n",
            "Он взял ее за руку и повел в сторону лестницы. - Я так и знал, что ты придёшь! - крикнул он. - Я так и знал! Ты же любишь его! - А ты не можешь любить меня? - Я знаю, - тихо произнесла она. - Но я люблю тебя, и не знаю, как это сделать. - Не нужно, - тихо сказала она. - Я люблю тебя. - И я тебя, - ответила она. *** - Ну что, ты готова? - Да. - Тогда я жду тебя в коридоре, - сказал он. - Я знаю, что ты не любишь, и ты не можешь любить меня, - прошептала она. - А я люблю тебя. - Я тоже тебя люблю, - сказала она. - Но, - сказала она, - ты не должна меня ненавидеть. - Но, - сказала она. - А я люблю тебя, и ты мне это говоришь, - сказала она. - Я знаю. - Я тоже тебя люблю. - И я тебя.\n",
            "- Ты\n",
            "Context >>> "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kpMtmoxvQ3a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}